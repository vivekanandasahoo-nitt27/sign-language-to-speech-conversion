# ğŸ¤Ÿ Sign Language to Speech Conversion System  

**MediaPipe Â· ANN Â· Groq LLM Â· ElevenLabs Â· Flask Â· Docker Â· AWS CI/CD**

A full-stack **Sign Language to Speech** web application that detects hand gestures from images, videos, or live webcam input, converts them into text using **hand-landmarkâ€“based ANN classification**, refines sentences using **Groq LLM**, and finally converts text into **natural human-like speech using ElevenLabs**.

> ğŸš€ Built for **accuracy, scalability, and production deployment**.

---

## âœ¨ Key Features

- âœ‹ **MediaPipe hand landmark extraction** (supports **2 hands**)
- ğŸ§  **ANN-based gesture classification** (landmark-driven, not raw images)
- ğŸ“ **Normalized & scale-invariant hand pose features**
- ğŸ§  **Groq LLM** for sentence and grammar refinement
- ğŸ”Š **ElevenLabs Text-to-Speech**
- ğŸŒ **Flask web application**
- ğŸ³ **Dockerized deployment**
- â˜ï¸ **AWS EC2 + ECR**
- ğŸ” **GitHub Actions CI/CD**
- ğŸ” Secure API key handling via environment variables

---

## ğŸ§  System Architecture

Image / Video / Webcam
â†“
MediaPipe Hands
(21 landmarks Ã— 2 hands)
â†“
Landmark Normalization

Wrist-relative

Unit scaling

Zero padding
â†“
ANN Classifier (126 features)
â†“
Raw Text Prediction
â†“
Groq LLM (NLP Refinement)
â†“
Final Sentence
â†“
ElevenLabs TTS
â†“
Speech Output ğŸ”Š


---

## âœ‹ Landmark Extraction Pipeline

- Detect up to **2 hands per frame**
- Extract **21 landmarks per hand** `(x, y, z)`
- Normalize landmarks:
  - Relative to wrist
  - Scale-invariant normalization
- If one hand is missing â†’ **zero-pad**
- Final feature vector size:

2 Ã— 21 Ã— 3 = 126 features


Saved as `.npy` files per label.

---

## ğŸ§  ANN Model Architecture

Input (126)
â†“
Dense(256) + BatchNorm + Dropout(0.3)
â†“
Dense(128) + BatchNorm + Dropout(0.25)
â†“
Dense(64)
â†“
Dense(N classes) + Softmax


### ğŸ”§ Training Configuration

| Parameter | Value |
|--------|------|
Epochs | 80 |
Batch Size | 32 |
Optimizer | Adam |
Learning Rate | 1e-3 |
Loss | Categorical Crossentropy |
Validation Split | 20% |
Callbacks | EarlyStopping, ReduceLROnPlateau |

---

## ğŸ§  NLP with Groq

- Refines:
  - Broken words
  - Partial predictions
  - Contextual meaning
- Converts raw gesture outputs into **human-readable sentences**
- Applied **after classification**, not during model inference

---

## ğŸ”Š Text-to-Speech (ElevenLabs)

- High-quality natural speech synthesis
- Converts refined sentences into audio
- API key injected securely via environment variables

---

## ğŸ§° Tech Stack

### ğŸ”¹ Backend & ML
- Python 3.9+
- Flask
- TensorFlow / Keras
- MediaPipe
- OpenCV
- NumPy
- Scikit-learn

### ğŸ”¹ NLP & Speech
- Groq API (LLM)
- ElevenLabs API (TTS)

### ğŸ”¹ DevOps
- Docker
- GitHub Actions
- AWS EC2
- AWS ECR
- IAM Roles

---

## ğŸ“ Project Structure

sign-language-to-speech-conversion/
â”‚
â”œâ”€â”€ app.py # Flask inference server
â”œâ”€â”€ extract_landmarks.py # MediaPipe landmark extraction
â”œâ”€â”€ train_model.py # ANN training
â”œâ”€â”€ modelnet_model.h5 # Trained model
â”œâ”€â”€ scaler.pkl # Feature scaler
â”œâ”€â”€ labels.json # Label mappings
â”‚
â”œâ”€â”€ data/ # Raw dataset
â”œâ”€â”€ landmark_data/ # Extracted landmarks
â”‚
â”œâ”€â”€ templates/ # HTML templates
â”œâ”€â”€ static/ # CSS / JS
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ .github/workflows/
â”‚ â””â”€â”€ deploy.yml # CI/CD pipeline
â”‚
â””â”€â”€ README.md


---

## ğŸ›  Local Setup

### 1ï¸âƒ£ Create Environment
```bash
conda create -n sign_lang python=3.9 -y
conda activate sign_lang
2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
ğŸ¯ Landmark Extraction
python extract_landmarks.py
ğŸ“ Train the ANN Model
python train_model.py
â–¶ï¸ Run the Application
python app.py
Open:

http://127.0.0.1:5000
ğŸ³ Docker Usage
Build Image
docker build -t sign-language-app .
Run Container
docker run -p 5000:5000 \
-e GROQ_API_KEY=your_key \
-e ELEVENLABS_API_KEY=your_key \
sign-language-app
â˜ï¸ AWS Deployment
Docker images stored in Amazon ECR

EC2 pulls images using IAM Role

App exposed via port 80

No SSH in CI/CD

ğŸ” CI/CD Pipeline
Trigger: git push to main

GitHub Actions:

Build Docker image

Push to ECR

EC2 auto-deploys latest image

ğŸ“Š Performance (Observed)
Scenario	Accuracy
Images	95%+
Videos	90%+
Live Webcam	85â€“92%
ğŸ” Security Practices
âŒ No API keys in code

âœ… Environment variables only

âœ… IAM Role for EC2

âŒ No .pem in GitHub

âœ… GitHub Secrets for CI/CD

ğŸ‘¨â€ğŸ’» Author
Vivekananda Sahoo
Machine Learning Engineer
Deep Learning Â· Computer Vision Â· MLOps

â­ Future Enhancements
Sentence-level temporal modeling (LSTM / Transformer)

Real-time streaming API

Mobile application

ONNX / TensorRT optimization




