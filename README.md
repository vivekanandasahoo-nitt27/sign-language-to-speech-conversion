ğŸ¤Ÿ Sign Language to Speech Conversion System

MediaPipe + ANN + Groq NLP + ElevenLabs + Flask + Docker + AWS CI/CD

A full-stack Sign Language to Speech web application that detects hand gestures from images, videos, or live webcam input, converts them into text using hand landmarkâ€“based ANN classification, refines sentences using Groq LLM, and finally converts text into natural speech using ElevenLabs.

Designed with scalability, accuracy, and production deployment in mind.

ğŸš€ Key Highlights

âœ‹ MediaPipe Hand Landmark Extraction (2 hands supported)

ğŸ§  ANN-based gesture classification (landmark-driven, not raw images)

ğŸ“ Normalized & scale-invariant hand pose features

ğŸ§  Groq LLM for word & sentence refinement

ğŸ”Š ElevenLabs text-to-speech output

ğŸŒ Flask-based web application

ğŸ³ Dockerized deployment

â˜ï¸ AWS EC2 + ECR + GitHub Actions CI/CD

ğŸ” Secure API key handling via environment variables

ğŸ§  System Architecture (Updated)
Input (Image / Video / Webcam)
        â†“
MediaPipe Hands
(21 landmarks Ã— 2 hands)
        â†“
Landmark Normalization
- Wrist-relative
- Unit-scale normalization
- Zero-padding for single hand
        â†“
ANN Classifier (126 features)
        â†“
Raw Text Prediction
        â†“
Groq LLM (NLP Refinement)
        â†“
Grammatically Correct Sentence
        â†“
ElevenLabs TTS
        â†“
Speech Output ğŸ”Š

ğŸ§© Landmark Extraction Pipeline

Detect up to 2 hands per frame

Extract 21 landmarks per hand (x, y, z)

Normalize landmarks:

Relative to wrist

Scale to unit distance

Pad missing hand with zeros

Final feature vector:

2 hands Ã— 21 landmarks Ã— 3 = 126 features


ğŸ“ Output stored as .npy files per label.

ğŸ§  ANN Model Architecture
Input: 126 landmark features
â†“
Dense(256) + BatchNorm + Dropout(0.3)
â†“
Dense(128) + BatchNorm + Dropout(0.25)
â†“
Dense(64)
â†“
Dense(N classes) + Softmax

Training Configuration
Parameter	Value
Epochs	80
Batch Size	32
Optimizer	Adam
Learning Rate	1e-3
Loss	Categorical Crossentropy
Validation Split	20%
Callbacks	EarlyStopping, ReduceLROnPlateau
ğŸ§  NLP with Groq

Refines:

Broken words

Incomplete sequences

Contextual meaning

Converts gesture outputs into human-readable sentences

Integrated after prediction, not during classification

ğŸ”Š Text-to-Speech (ElevenLabs)

Converts refined text to natural speech

High-quality voice synthesis

API key injected securely via environment variables

ğŸ§° Tech Stack
Backend & ML

Python 3.9+

Flask

TensorFlow / Keras

MediaPipe

OpenCV

NumPy

Scikit-learn

NLP & Speech

Groq API (LLM)

ElevenLabs API (TTS)

DevOps

Docker

GitHub Actions (CI/CD)

AWS EC2

AWS ECR

IAM Roles (no hardcoded AWS keys)

ğŸ“ Project Structure
sign-language-to-speech-conversion/
â”‚
â”œâ”€â”€ app.py                    # Flask inference server
â”œâ”€â”€ extract_landmarks.py      # MediaPipe landmark extraction
â”œâ”€â”€ train_model.py            # ANN training script
â”œâ”€â”€ modelnet_model.h5         # Trained ANN model
â”œâ”€â”€ scaler.pkl                # Feature standard scaler
â”œâ”€â”€ labels.json               # Class labels
â”‚
â”œâ”€â”€ landmark_data/            # Extracted landmark features
â”œâ”€â”€ data/                     # Raw image dataset
â”‚
â”œâ”€â”€ templates/                # HTML templates
â”œâ”€â”€ static/                   # CSS / JS assets
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ deploy.yml             # GitHub Actions CI/CD
â”‚
â””â”€â”€ README.md

ğŸ›  Local Setup
1ï¸âƒ£ Create Environment
conda create -n sign_lang python=3.9 -y
conda activate sign_lang

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

ğŸ¯ Landmark Extraction
python extract_landmarks.py


Outputs:

landmark_data/

labels.json

ğŸ“ Train the ANN Model
python train_model.py


Outputs:

modelnet_model.h5

scaler.pkl

labels.json

â–¶ï¸ Run the Application
python app.py


Open in browser:

http://127.0.0.1:5000

ğŸ³ Docker Usage
Build Image
docker build -t sign-language-app .

Run Container
docker run -p 5000:5000 \
-e GROQ_API_KEY=your_key \
-e ELEVENLABS_API_KEY=your_key \
sign-language-app

â˜ï¸ AWS Deployment (EC2 + ECR)

Docker image pushed to Amazon ECR

EC2 instance pulls image using IAM Role

App runs on port 80

CI/CD handled via GitHub Actions

ğŸ” CI/CD Pipeline (GitHub Actions)

Trigger: git push to main

Steps:

Checkout code

Build Docker image

Push to Amazon ECR

EC2 auto-deploys latest image

No SSH. No .pem in GitHub. Secure & scalable.

ğŸ“Š Performance (Observed)
Metric	Accuracy
Image-based prediction	95%+
Video prediction	90%+
Real-world webcam	85â€“92%
ğŸ” Security Best Practices

âŒ No API keys in code

âœ… Environment variables only

âœ… IAM Roles for EC2

âŒ No .pem keys in GitHub

âœ… Secrets managed via GitHub Actions

ğŸ‘¨â€ğŸ’» Author

Vivekananda Sahoo
Machine Learning Engineer
Deep Learning â€¢ Computer Vision â€¢ MLOps

â­ Future Enhancements

Sentence-level temporal modeling (LSTM / Transformer)

Real-time streaming API

Mobile app (Flutter / React Native)

ONNX / TensorRT optimization

GPU-based EC2 inference

If you want, next I can:

âœ¨ Optimize this for resume / LinkedIn

ğŸ“‰ Reduce Docker image size

ğŸ” Add versioned rollback

ğŸ“Š Add monitoring & logs

Just tell me ğŸ‘Œ